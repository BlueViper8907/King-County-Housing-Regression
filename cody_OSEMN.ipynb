{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# King County Housing Regression Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Of Contents\n",
    "<font size=3rem>\n",
    "    \n",
    "0 -**[ INTRO](#INTRODUCTION)<br>**\n",
    "1 -**[ OBTAIN](#OBTAIN)**<br>\n",
    "2 -**[ SCRUB](#SCRUB)**<br>\n",
    "3 -**[ EXPLORE](#EXPLORE)**<br>\n",
    "4 -**[ MODEL](#MODEL)**<br>\n",
    "5 -**[ INTERPRET](#INTERPRET)**<br>\n",
    "6 -**[ CONCLUSIONS & RECCOMENDATIONS](#CONCLUSIONS-&-RECOMMENDATIONS)<br>**\n",
    "</font>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Students: Cody Freese/Fennec Nightingale/Thomas Cornett\n",
    "* Pace: Part time\n",
    "* Instructor: Amber Yandow\n",
    "* Blog post URL:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> What factors impact the price of a home?</p>\n",
    "<p> What factors impact the price of a home for different income levels?</p>\n",
    "<p> If you're looking to move your family to king county, where is the best bang for your buck?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos, sqrt, atan2, radians\n",
    "from sklearn import svm\n",
    "from scipy.stats import zscore\n",
    "from sklearn import linear_model\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_predict, KFold, train_test_split\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editing our settings \n",
    "We have too many columns to view normally, and it's difficult to get a good grasp of our data with how much is normally cut off. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBTAIN DATA\n",
    "Here we'll be working with the King County housing data provided to us by FlatIron and data about schools in King County gathered by ArcGis. We'll be importing them via the Pandas library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrote up our data types to save on computer space and stop some of them from being inccorectly read as objs\n",
    "kc_dtypes = {'id': int, 'date' : str,  'price': float, 'bedrooms' : int, 'bathrooms' : float, 'sqft_living': int, 'sqft_lot': int, \n",
    "             'floors': float, 'waterfront': float, 'view' : float, 'condition': float, 'grade': int, 'sqft_above': int, \n",
    "             'yr_built': int, 'yr_renovated': float, 'zipcode': float, 'lat': float, 'long': float}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_data = pd.read_csv(r'~\\Documents\\Flatiron\\data\\data\\kc_house_data.csv', parse_dates = ['date'], dtype=kc_dtypes)\n",
    "schools = pd.read_csv(r'~\\Documents\\Flatiron\\data\\data\\Schools.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all of the data we need to start. Now we'll be adding the last of our data, calculating the distance between the schools and our homes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6070a3885565>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m641\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mlat2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mradians\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mschools\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LAT_CEN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mlon2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mradians\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mschools\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LONG_CEN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mdlon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlon2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlon1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2869\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2870\u001b[1;33m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2871\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#calculate distance between schools and data \n",
    "kc = {}\n",
    "kc5 = {}\n",
    "# approximate radius of earth in miles  miles\n",
    "i = 0\n",
    "#iterate over each of our rows in the dataframe\n",
    "while i <= 21480:\n",
    "    R = 3963.0\n",
    "    k = 0\n",
    "    lat1 = radians(kc_data['lat'].iloc[i])\n",
    "    lon1 = radians(kc_data['long'].iloc[i])\n",
    "    distance = []\n",
    "    #iterate over each school to see which school is the closest to each row in our datframe \n",
    "    while k <= 641:\n",
    "        lat2 = radians(schools['LAT_CEN'].iloc[k])\n",
    "        lon2 = radians(schools['LONG_CEN'].iloc[k])\n",
    "\n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "\n",
    "        a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "        c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "        distance.append(R * c)\n",
    "        \n",
    "        k += 1 \n",
    "    #sort schools by distance \n",
    "    distance.sort()\n",
    "    #choose closest school \n",
    "    kc[i] = distance[0:1]\n",
    "    #find some of distance to nearest 5 schools \n",
    "    kc5[i] = sum(distance[0:5])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we turn those distances into a dataframe, so we can join them with the rest of our data and match them with the houses they belong to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc1 = pd.DataFrame.from_dict(kc, orient='index', columns=['mi_nearest_scl'])\n",
    "kc5 = pd.DataFrame.from_dict(kc5, orient='index', columns=['mi_5_scls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_data = kc_data.merge(kc1, left_index=True, right_index=True)\n",
    "kc_data = kc_data.merge(kc5, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking to see if maybe percentile matters in terms of distance, as most of our hoems are relitively close \n",
    "kc_data['prcnt_2_scl'] = kc_data['mi_nearest_scl'].rank(pct = True) \n",
    "kc_data['prcnt_2_5_scls'] = kc_data['mi_5_scls'].rank(pct = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at our data to see what we are working with and what we might need to fix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrub\n",
    "Cleaning up our data, filling NaN values, dropping unnecessary columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_data = kc_data.drop(['id', 'date'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#to use sqft basment later on we need to convert it to a float \n",
    "kc_data['sqft_basement'] = kc_data['sqft_basement'].replace({'?': 0})\n",
    "kc_data['sqft_basement'] = kc_data['sqft_basement'].astype(dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we have 3 columns with null values, after exploring them, it makes the most sense to fill the null values with zeros, which is what they had been using to indicate a column without anything anyways. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_data = kc_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to integer for whole number year, not sure why it'll let us reassign it here but raise errors in dtypes\n",
    "kc_data['yr_renovated'] = kc_data['yr_renovated'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding dummy variables of our catagorical data so we can use them in our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing condition to be a good or bad, hoping that'll help get rid of the multicolinearity \n",
    "kc_data['condition'] = kc_data.condition.replace(to_replace = [1.0, 2.0, 3.0, 4.0, 5.0],  value= ['bad', 'bad', 'good', 'good', 'good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have 70 zipcodes and 120 years, it would add too much complexity to our data to increase it by 190 columns\n",
    "# so instead, we're going to go through and bin them! \n",
    "zips = []\n",
    "years = []\n",
    "\n",
    "\n",
    "for zipcode in kc_data.zipcode:\n",
    "    zips.append(zipcode)\n",
    "for year in kc_data.yr_built:\n",
    "    years.append(year)\n",
    "    \n",
    "zips = list(set(zips))\n",
    "years = list(set(years))\n",
    "\n",
    "zips.sort()\n",
    "years.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will have to find a way to write this into a loop at some point, but, I can't figure out how to get .replace()\n",
    "#to adequatley read lists of lists while also giving them unique names, so for now this works \n",
    "kc_data['zipcode'] = kc_data.zipcode.replace(to_replace = zips[0:5],  value= 'zip001t005')\n",
    "kc_data['zipcode'] = kc_data.zipcode.replace(to_replace = zips[5:10], value= 'zip006t011')\n",
    "kc_data['zipcode'] = kc_data.zipcode.replace(to_replace = zips[10:15], value= 'zip014t024')\n",
    "kc_data['zipcode'] = kc_data.zipcode.replace(to_replace = zips[15:20], value= 'zip027t031')\n",
    "kc_data['zipcode'] = kc_data.zipcode.replace(to_replace = zips[20:25], value= 'zip032t039')\n",
    "kc_data['zipcode'] = kc_data.zipcode.replace(to_replace = zips[25:30], value= 'zip040t053')\n",
    "kc_data['zipcode'] = kc_data.zipcode.replace(to_replace = zips[30:35], value= 'zip055t065')\n",
    "kc_data['zipcode'] = kc_data.zipcode.replace(to_replace = zips[35:40], value= 'zip070t077')\n",
    "kc_data['zipcode'] = kc_data.zipcode.replace(to_replace = zips[40:45], value= 'zip092t106')\n",
    "kc_data['zipcode'] = kc_data.zipcode.replace(to_replace = zips[45:50], value= 'zip107t115')\n",
    "kc_data['zipcode'] = kc_data.zipcode.replace(to_replace = zips[50:55], value= 'zip116t122')\n",
    "kc_data['zipcode'] = kc_data.zipcode.replace(to_replace = zips[55:60], value= 'zip125t144')\n",
    "kc_data['zipcode'] = kc_data.zipcode.replace(to_replace = zips[60:65], value= 'zip146t168')\n",
    "kc_data['zipcode'] = kc_data.zipcode.replace(to_replace = zips[65:70], value= 'zip177t199')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gonna do the same for year built by 20 years, will give us 6 new columns, may be illuminating \n",
    "kc_data['yr_built'] = kc_data.yr_built.replace(to_replace = years[0:20], value= 'thru20')\n",
    "kc_data['yr_built'] = kc_data.yr_built.replace(to_replace = years[20:40], value= 'thru40')\n",
    "kc_data['yr_built'] = kc_data.yr_built.replace(to_replace = years[40:60], value= 'thru60')\n",
    "kc_data['yr_built'] = kc_data.yr_built.replace(to_replace = years[60:80], value= 'thru80')\n",
    "kc_data['yr_built'] = kc_data.yr_built.replace(to_replace = years[80:100], value= 'thru2000')\n",
    "kc_data['yr_built'] = kc_data.yr_built.replace(to_replace = years[100:120], value= 'thru2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies of our new variables \n",
    "dummys = ['zipcode', 'yr_built', 'condition', ]\n",
    "\n",
    "for dummy in dummys:\n",
    "    dumm = pd.get_dummies(kc_data[dummy], drop_first=True)\n",
    "    kc_data = kc_data.merge(dumm, left_index=True, right_index=True)\n",
    "\n",
    "#we're doing something unique to these variables so it wouldn't save us any time to put them into a loop\n",
    "dumm = pd.get_dummies(kc_data['view'], prefix='view', drop_first=True, dtype=int)\n",
    "kc_data = kc_data.merge(dumm, left_index=True, right_index=True)\n",
    "dumm = pd.get_dummies(kc_data['grade'], prefix='gra', drop_first=True, dtype=int)\n",
    "kc_data = kc_data.merge(dumm, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#break up variables into diverse ranges & renaming our dummies so that they'r easier to interpret \n",
    "kc_data = kc_data.rename({'view_1.0': 'view1', 'view_2.0': 'view2', 'view_3.0': 'view3', 'view_4.0':'view4'},axis=1)\n",
    "kc_data = kc_data.rename({'gra_4': 'D', 'gra_5':'Cmin', 'gra_6':'C','gra_7':'Cpl', 'gra_8':'Bmin', 'gra_9':'B',\n",
    "                          'gra_10':'Bpl', 'gra_11':'Amin', 'gra_12':'A', 'gra_13':'Apl'},axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLORE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of the data we'll need ready to go we can really start digging in and checking it out! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_data.hist(figsize=(10,10))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pd.plotting.scatter_matrix(kc_data,figsize=(16,16));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,12))\n",
    "corr = kc_data.corr().abs().round(3)\n",
    "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "sns.heatmap(corr, annot=True, mask=mask, cmap='Oranges', ax=ax)\n",
    "plt.setp(ax.get_xticklabels(), \n",
    "         rotation=45, \n",
    "         ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "ax.set_title('Correlations')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see some colinearity between our features, it's best to either remove or transform them if we want to use them in our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to multiply by basement to try and get rid of the correlation, we'd be multiplying by a bunch of zeros and it wouldn't adequetly represent our data. By adding one to every 'sqft_basement' that is equal to zero, when we multiply if there are no basement values we still keep our 'sqft_above' values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_data['sqft_basement'] = kc_data['sqft_basement'].map(lambda x :  1 if x == 0 else x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting rid of multicolinearity in sqftage \n",
    "kc_data['sqft_total'] = kc_data['sqft_living']*kc_data['sqft_lot']\n",
    "kc_data['sqft_neighb'] = kc_data['sqft_living15']*kc_data['sqft_lot15']\n",
    "kc_data['sqft_habitable'] = kc_data['sqft_above']*kc_data['sqft_basement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print columns we will be using going forward \n",
    "#make a copy of the dataframe holding only columns we'll be including\n",
    "kc_data.columns\n",
    "kc_data = kc_data[['price', 'bedrooms', 'bathrooms', 'floors','waterfront', \n",
    "                   'yr_renovated', 'lat', 'long', \n",
    "                   'sqft_total', 'sqft_neighb', 'sqft_habitable', \n",
    "                   'good', 'view1', 'view2', 'view3', 'view4', \n",
    "                   'D', 'Cmin', 'C', 'Cpl', 'Bmin', 'B', 'Bpl', 'Amin', \n",
    "                   'zip006t011', 'zip014t024', 'zip027t031', 'zip032t039', \n",
    "                   'zip040t053', 'zip055t065', 'zip070t077', 'zip092t106', \n",
    "                   'zip107t115', 'zip116t122', 'zip125t144', 'zip146t168', \n",
    "                   'zip177t199', \n",
    "                   'thru2000', 'thru2020', 'thru40', 'thru60', 'thru80'\n",
    "                  ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Model on Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowtier = kc_data[kc_data.price <=300000]\n",
    "midtier = kc_data[(kc_data.price > 300001) & (kc_data.price<=800000) ]\n",
    "hightier = kc_data[kc_data.price >800000]\n",
    "\n",
    "lowincome = ['bedrooms', 'bathrooms', 'floors', 'waterfront', \n",
    "          'yr_renovated', 'lat', 'long', \n",
    "          'sqft_total', 'sqft_neighb', 'sqft_habitable', \n",
    "          'good', 'view1', 'view2', 'view3', 'view4', \n",
    "          'D', 'Cmin', 'C', 'Cpl', 'Bmin', 'B', 'Bpl', 'Amin',  \n",
    "          'zip006t011', 'zip014t024', 'zip027t031', 'zip032t039', \n",
    "          'zip040t053', 'zip055t065', 'zip070t077', 'zip092t106', \n",
    "          'zip107t115', 'zip116t122', 'zip125t144', 'zip146t168', \n",
    "          'zip177t199', \n",
    "          'thru2000', 'thru2020', 'thru40', 'thru60', 'thru80',\n",
    "          'mi_nearest_scl']\n",
    "\n",
    "mediumincome = ['bedrooms', 'bathrooms', 'floors', 'waterfront', \n",
    "          'yr_renovated', 'lat', 'long', \n",
    "          'sqft_total', 'sqft_neighb', 'sqft_habitable', \n",
    "          'good', 'view1', 'view2', 'view3', 'view4', \n",
    "          'D', 'Cmin', 'C', 'Cpl', 'Bmin', 'B', 'Bpl', 'Amin',  \n",
    "          'zip006t011', 'zip014t024', 'zip027t031', 'zip032t039', \n",
    "          'zip040t053', 'zip055t065', 'zip070t077', 'zip092t106', \n",
    "          'zip107t115', 'zip116t122', 'zip125t144', 'zip146t168', \n",
    "          'zip177t199', \n",
    "          'thru2000', 'thru2020', 'thru40', 'thru60', 'thru80',\n",
    "          'mi_nearest_scl']\n",
    "\n",
    "highincome = ['bedrooms', 'bathrooms', 'floors', 'waterfront', \n",
    "          'yr_renovated', 'lat', 'long', \n",
    "          'sqft_total', 'sqft_neighb', 'sqft_habitable', \n",
    "          'good', 'view1', 'view2', 'view3', 'view4', \n",
    "          'D', 'Cmin', 'C', 'Cpl', 'Bmin', 'B', 'Bpl', 'Amin',  \n",
    "          'zip006t011', 'zip014t024', 'zip027t031', 'zip032t039', \n",
    "          'zip040t053', 'zip055t065', 'zip070t077', 'zip092t106', \n",
    "          'zip107t115', 'zip116t122', 'zip125t144', 'zip146t168', \n",
    "          'zip177t199', \n",
    "          'thru2000', 'thru2020', 'thru40', 'thru60', 'thru80',\n",
    "          'mi_nearest_scl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ols(df, x_columns, drops=None, target='price', add_constant=False):\n",
    "    if drops:\n",
    "        drops.append(target)\n",
    "        X = df.drop(columns=drops)\n",
    "    else:\n",
    "        X = df[x_columns]\n",
    "    if add_constant:\n",
    "        X = sm.add_constant(X)\n",
    "    y = df[target]\n",
    "    ols = sm.OLS(y, X)\n",
    "    model = ols.fit()\n",
    "    display(model.summary())\n",
    "    fig = sm.graphics.qqplot(model.resid, dist=stats.norm, line='45', alpha=.05, fit=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_tiers = [('low', lowtier, lowincome), \n",
    "               ('mid', midtier, mediumincome), \n",
    "               ('high', hightier, highincome)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, tier, income in price_tiers:\n",
    "    print(name.upper())\n",
    "    make_ols(tier, income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refinement\n",
    "First we're going to start filtering out outliers, helping normalize our data should improve our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['price']:\n",
    "    col_zscore = str(col + '_zscore')\n",
    "    kc_data[col_zscore] = (kc_data[col] - kc_data[col].mean())/kc_data[col].std()\n",
    "    kc_data = kc_data.loc[kc_data[col_zscore] < 2.5]\n",
    "    kc_data = kc_data.loc[kc_data[col_zscore] > (-2.5)]\n",
    "    kc_data = kc_data.drop(col_zscore, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "plt.plot(kc_data['price'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,100):\n",
    "    q = i / 100\n",
    "    print('{} percentile: {}'.format(q, kc_data['sqft_neighb'].quantile(q=q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in bedrooms, we can clearly see a single outlier that is likely just a typo \n",
    "kc_data[kc_data['bedrooms'] == 33]\n",
    "# wouldn't be realistic for a house with 33 bedrooms to only have a sqft_living of 1620 and only 1 3/4 bathrooms so we will adjust to 3 \n",
    "kc_data[kc_data['bedrooms'] == 33] = kc_data[kc_data['bedrooms'] == 33].replace(33,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to fix other outliers we will explore our data and find cutoffs that seem reasonable \n",
    "kc_data = kc_data.loc[kc_data['sqft_total'] <= 3.000000e+07] \n",
    "kc_data = kc_data.loc[kc_data['sqft_total'] >= 500000]\n",
    "kc_data = kc_data.loc[kc_data['sqft_neighb'] <= 2.500000e+07]\n",
    "kc_data = kc_data.loc[kc_data['sqft_habitable'] >= 500000]\n",
    "kc_data = kc_data.loc[kc_data['sqft_habitable'] <= 2000000]\n",
    "kc_data =  kc_data.loc[kc_data['bathrooms'] >= 1]\n",
    "kc_data =  kc_data.loc[kc_data['bathrooms'] <= 5.5]\n",
    "kc_data =  kc_data.loc[kc_data['bedrooms'] <= 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowtier = kc_data[(kc_data.price > 210000) & (kc_data.price<=348000) ]\n",
    "midtier = kc_data[(kc_data.price > 348000) & (kc_data.price<=480000) ]\n",
    "uppermidtier = kc_data[(kc_data.price > 480000) & (kc_data.price<=664000) ]\n",
    "hightier = kc_data[(kc_data.price >664000) & (kc_data.price<=1080000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowincome = ['bathrooms', 'lat', 'long',  'sqft_habitable', \n",
    "             'view1', 'view2', 'view3', 'Cpl', 'Bmin', 'B', \n",
    "             'Bpl', 'Amin', 'zip055t065', 'zip092t106',\n",
    "             'zip107t115', 'zip116t122', 'zip146t168']\n",
    "\n",
    "mediumincome = ['bathrooms', 'waterfront',  'lat', 'long', \n",
    "                'view2', 'Bmin', 'B', 'Bpl', 'Amin', \n",
    "                'zip006t011', 'zip032t039', 'zip040t053', \n",
    "                'zip070t077',  'zip107t115', 'zip116t122', \n",
    "                'zip125t144', 'thru2000', 'thru60', 'thru80']\n",
    "\n",
    "uppermedincome = ['bathrooms', 'long', 'sqft_habitable',\n",
    "                  'Cpl', 'Bmin', 'B', 'Bpl',\n",
    "                  'zip014t024', 'zip146t168', \n",
    "                  'zip055t065', 'zip070t077', 'zip125t144', \n",
    "                  'thru2000', 'thru2020', 'thru80']\n",
    "\n",
    "highincome = ['bathrooms', 'floors', 'sqft_neighb', \n",
    "              'sqft_habitable', 'Amin', 'thru2020',\n",
    "              'zip006t011', 'zip027t031',  'zip070t077', \n",
    "              'zip107t115', 'zip116t122', 'zip177t199']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_tiers = [('low', lowtier, lowincome), \n",
    "               ('mid', midtier, mediumincome), \n",
    "               ('upmid', uppermidtier, uppermedincome),\n",
    "               ('high', hightier, highincome)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, tier, income in price_tiers:\n",
    "    print(name.upper())\n",
    "    make_ols(tier, income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_ols(hightier, highincome)\n",
    "model = make_ols(lowtier, lowincome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('test R Squared: ' + str(round(r2_score(X_test, y_test), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "fig = sm.graphics.plot_regress_exog(model, \"Bpl\", fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "fig = sm.graphics.plot_regress_exog(model, \"bathrooms\", fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "fig = sm.graphics.plot_regress_exog(model, \"lat\", fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "fig = sm.graphics.plot_regress_exog(model, \"long\", fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(15,8))\n",
    "# fig = sm.graphics.plot_regress_exog(model, \"sqft_total\", fig=fig)\n",
    "# plt.show()\n",
    "lowtier.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "fig = sm.graphics.plot_regress_exog(model, \"sqft_habitable\", fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "fig = sm.graphics.plot_regress_exog(model, \"Bmin\", fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowtier['sqft_total'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Split Test - High Tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first step\n",
    "training_data, testing_data = train_test_split(hightier, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split columns\n",
    "target = 'price'\n",
    "predictive_cols = training_data.drop(target, axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "predictors = '+'.join(predictive_cols)\n",
    "formula = target + '~' + predictors\n",
    "model = ols(formula=formula, data=training_data).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "y_pred_train = model.predict(training_data[predictive_cols])\n",
    "y_pred_test = model.predict(testing_data[predictive_cols])\n",
    "# then get the scores:\n",
    "train_mse = mean_squared_error(training_data[target], y_pred_train)\n",
    "test_mse = mean_squared_error(testing_data[target], y_pred_test)\n",
    "print('Training MSE:', train_mse, '\\nTesting MSE:', test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Split Test - Medium Tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first step\n",
    "training_data, testing_data = train_test_split(midtier, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split columns\n",
    "target = 'price'\n",
    "predictive_cols = training_data.drop(target, axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "predictors = '+'.join(predictive_cols)\n",
    "formula = target + '~' + predictors\n",
    "model = ols(formula=formula, data=training_data).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "y_pred_train = model.predict(training_data[predictive_cols])\n",
    "y_pred_test = model.predict(testing_data[predictive_cols])\n",
    "# then get the scores:\n",
    "train_mse = mean_squared_error(training_data[target], y_pred_train)\n",
    "test_mse = mean_squared_error(testing_data[target], y_pred_test)\n",
    "print('Training MSE:', train_mse, '\\nTesting MSE:', test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Split Test - Low Tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first step\n",
    "training_data, testing_data = train_test_split(lowtier, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split columns\n",
    "target = 'price'\n",
    "predictive_cols = training_data.drop(target, axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "predictors = '+'.join(predictive_cols)\n",
    "formula = target + '~' + predictors\n",
    "model = ols(formula=formula, data=training_data).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "y_pred_train = model.predict(training_data[predictive_cols])\n",
    "y_pred_test = model.predict(testing_data[predictive_cols])\n",
    "# then get the scores:\n",
    "train_mse = mean_squared_error(training_data[target], y_pred_train)\n",
    "test_mse = mean_squared_error(testing_data[target], y_pred_test)\n",
    "print('Training MSE:', train_mse, '\\nTesting MSE:', test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTERPRET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.boxplot(x='grade', y='price', data=kc_data)\n",
    "ax.set(title='Grade relationship on Price', \n",
    "       xlabel='Grade', ylabel='Price')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.boxplot(x='bathrooms', y='price', data=kc_data)\n",
    "ax.set(title='Bathrooms & Price', \n",
    "       xlabel='Bathrooms', ylabel='Price')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.boxplot(x='bedrooms', y='price', data=kc_data)\n",
    "ax.set(title='Bedrooms & Price', \n",
    "       xlabel='Bedrooms', ylabel='Price')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.boxplot(x='floors', y='price', data=kc_data)\n",
    "ax.set(title='Floors & Price', \n",
    "       xlabel='Floors', ylabel='Price')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.boxplot(x='condition', y='price', data=kc_data)\n",
    "ax.set(title='Condition & Price', \n",
    "       xlabel='Condition', ylabel='Price')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.regplot(x='sqft_habitable', y='price', data=kc_data)\n",
    "ax.set(title='Square Habitable & Price', \n",
    "       xlabel='SqFt.', ylabel='Price')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.boxplot(x='yr_built', y='price', data=kc_data)\n",
    "ax.set(title='Year Built & Price', \n",
    "       xlabel='Year Built', ylabel='Price')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.boxplot(x='yr_renovated', y='price', data=kc_data)\n",
    "ax.set(title='Year Renovated & Price', \n",
    "       xlabel='Year', ylabel='Price')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "383.938px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
